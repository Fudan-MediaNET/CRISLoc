# train_test_generate.m
生成训练集和预测集
options = 'default': 只有幅值
options = 'difference' : 幅值 + 一阶差分

# train_test_generate.m
OUTPUT: accuracy 准确度
        error_dis 平均误差(假设一个方框是1*1)
options = 'default': 标准knn
options = 'correlation':互相关
options = 'weight': 因为赋值的绝对值比差分的绝对值大，所以做标准knn的话相当于赋值所占的权重较小。因此，我对每一个记录的幅值和差分部分分别归一化。存在的问题：每一条记录归一化时除以的系数都不同，这样可能会拉大相邻点之间的距离。结果并不如标准knn来得好。(或者说差分的区分度本来就不如幅值好)

# main.m
train_test_generate和train_test_generate的调用方法及测试结果

觉得可以改进的几个地方：
1. 在做knn的时候，在计算距离的时候，可以增大幅值大(即信号强)的接受端/发射端的权重
2. 考虑如果(是否需要)把差分放进去，或者可以对差分做互相关？
3. 之前有一篇论文是用SVM来做的，但是标准的SVM是做二分类器的，要用于我们localization的多分类器就要做M(36)个二分类器，我没来得及试
4. or直接弄个几层的网络，这样幅值和差分该用多少的网络也不用我们想了...

By the way，我觉得这结果有一点太好了。可能的原因是我把一次(70000以上)的数据里第10001-11000作为训练集，最后100个作为测试集，所以数据比较相似。我想你下次再测的时候可以在周围多走动一下...

如果要做transfer的话，我觉得可以把三个接收端的位置朝中心收拢一下，或者在周围加一些障碍物。(换接收端位置的时候最好在原来的地方做好标记)

以上是我的一点想法，你有什么想法就照你的做好了。做得开心就好:)